{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4rCKcndPybL"
      },
      "source": [
        "# Lab : Image Classification using Convolutional Neural Networks\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Creating deep networks using Keras\n",
        "*   Steps necessary in training a neural network\n",
        "*   Prediction and performance analysis using neural networks\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wkicuxZdrdq"
      },
      "source": [
        "# **Working with a new dataset: CIFAR-10**\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. More information about CIFAR-10 can be found [here](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "In Keras, the CIFAR-10 dataset is also preloaded in the form of four Numpy arrays. x_train and y_train contain the training set, while x_test and y_test contain the test data. The images are encoded as Numpy arrays and their corresponding labels ranging from 0 to 9.\n",
        "\n",
        "Your task is to:\n",
        "\n",
        "*   Visualize the images in CIFAR-10 dataset. Create a 10 x 10 plot showing 10 random samples from each class.\n",
        "*   Convert the labels to one-hot encoded form.\n",
        "*   Normalize the images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrb20KGMtTFq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# y_train = y_train.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Load Animals-10 dataset\n",
        "IMG_SIZE = (224, 224) # Resize images\n",
        "BATCH_SIZE = 32\n",
        "animals_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical', # Multi-class classification\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIefwf5caBL0",
        "outputId": "97c6050c-f85a-452a-b981-7f37af55a86b"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(x_train.ndim)\n",
        "print(x_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxoQduYfakzx",
        "outputId": "7a6f501c-3296-4082-8b07-95153d537cce"
      },
      "outputs": [],
      "source": [
        "print(x_test.shape)\n",
        "print(x_test.ndim)\n",
        "print(x_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDBplA28gIfV",
        "outputId": "eb81298b-712d-49e8-8bca-8627a363e25f"
      },
      "outputs": [],
      "source": [
        "#Convert the labels to one-hot encoded form.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "\n",
        "# Data Normalization (normalize the images)\n",
        "\n",
        "X_train = x_train.astype('float32')/255\n",
        "X_test = x_test.astype('float32')/255\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsAvv9smisuJ"
      },
      "outputs": [],
      "source": [
        "#The fourth parameter '3' in the above result represents 3 color channels RGB.\n",
        "#To convert the coloured images to gray scale images by doing this\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # X_train_gray = tf.image.rgb_to_grayscale(X_train)\n",
        "# # X_test_gray = tf.image.rgb_to_grayscale(X_test)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct6auff6kI07"
      },
      "outputs": [],
      "source": [
        "#To remove it, we can convert the coloured images to gray scale images by doing this\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "# X_train_gray = tf.squeeze(x_train)\n",
        "# X_test_gray = tf.squeeze(x_test)\n",
        "\n",
        "# print(X_train_gray.shape)\n",
        "# print(X_test_gray.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ER5WlMNRydp"
      },
      "source": [
        "## Define the following model (same as the one in tutorial)\n",
        "\n",
        "For the convolutional front-end, start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer.\n",
        "\n",
        "Use the input as (32,32,3).\n",
        "\n",
        "The filter maps can then be flattened to provide features to the classifier.\n",
        "\n",
        "Use a dense layer with 100 units before the classification layer (which is also a dense layer with softmax activation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NpU1Hf-e68f",
        "outputId": "ae669354-e610-4b56-bc33-4d7d96f3bb99"
      },
      "outputs": [],
      "source": [
        "#To define the model import the required libraries\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "input_shape = (32,32,3)\n",
        "\n",
        "model = Sequential(\n",
        "    [Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(100, activation='relu'),\n",
        "\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "fTxuXdHRe659",
        "outputId": "165e1253-b870-451b-994d-20eb12afa7b7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfWCHxh8HGhN"
      },
      "outputs": [],
      "source": [
        "# from keras.backend import clear_session\n",
        "# clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtivbQJT39U"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 50 epochs with a batch size of 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9Cm_l2ke63N"
      },
      "outputs": [],
      "source": [
        "#compile the model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn8UzPBZugVp",
        "outputId": "e07faf59-b586-4ba2-da30-232ead3efee3"
      },
      "outputs": [],
      "source": [
        "#train the model for 50 epochs with batch size of 512 and store the result in history\n",
        "\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=512, epochs=50, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJQ3J6kXaBL2"
      },
      "source": [
        "*   Plot the cross entropy loss curve and the accuracy curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "zQJ3jRuMxjUq",
        "outputId": "0626b153-7c19-4eb6-9675-2c42de55fdb6"
      },
      "outputs": [],
      "source": [
        "# Extract values from training history\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.title('Cross-Entropy Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIVis4Jy4h1b",
        "outputId": "781cd10b-6a44-434f-b691-6ca9bcbd35ec"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mrWK5hSB_o"
      },
      "source": [
        "## Defining Deeper Architectures: VGG Models\n",
        "\n",
        "*   Define a deeper model architecture for CIFAR-10 dataset and train the new model for 50 epochs with a batch size of 512. We will use VGG model as the architecture.\n",
        "\n",
        "Stack two convolutional layers with 32 filters, each of 3 x 3.\n",
        "\n",
        "Use a max pooling layer and next flatten the output of the previous layer and add a dense layer with 128 units before the classification layer.\n",
        "\n",
        "For all the layers, use ReLU activation function.\n",
        "\n",
        "Use same padding for the layers to ensure that the height and width of each layer output matches the input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFvBR0phyoUR"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfbI0OH5yoRx"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize images\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SNXlPR7ynsu"
      },
      "outputs": [],
      "source": [
        "#define the model\n",
        "vgg_model = keras.Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A80vLxW9FIek"
      },
      "outputs": [],
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgca5dUNSFNc"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwaPphEBUtlC"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 50 epochs with a batch size of 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02wJ_0ZC_1J0"
      },
      "outputs": [],
      "source": [
        "vgg_model.compile(optimizer=SGD(),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "210T8p6Z37Wq",
        "outputId": "1a57ad9f-5c40-42a2-fe6a-337cefe7b647"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "history_vgg = vgg_model.fit(x_train, y_train, batch_size=512, epochs=50, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cRr2ZFSFds"
      },
      "source": [
        "*   Compare the performance of both the models by plotting the loss and accuracy curves of both the training steps. Does the deeper model perform better? Comment on the observation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8OSHAf5SJPr"
      },
      "outputs": [],
      "source": [
        "acc1 = history.history['accuracy']\n",
        "val_acc1 = history.history['val_accuracy']\n",
        "loss1 = history.history['loss']\n",
        "val_loss1 = history.history['val_loss']\n",
        "\n",
        "acc2 = history_vgg.history['accuracy']\n",
        "val_acc2 = history_vgg.history['val_accuracy']\n",
        "loss2 = history_vgg.history['loss']\n",
        "val_loss2 = history_vgg.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc1) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "8gAGriXYE1lI",
        "outputId": "09eb4c17-bacf-467e-eac4-24a59537cbec"
      },
      "outputs": [],
      "source": [
        "# Plot Accuracy Comparison\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc1, label='Shallow Train Acc')\n",
        "plt.plot(epochs, val_acc1, label='Shallow Val Acc')\n",
        "plt.plot(epochs, acc2, label='VGG Train Acc')\n",
        "plt.plot(epochs, val_acc2, label='VGG Val Acc')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Loss Comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss1, label='Shallow Train Loss')\n",
        "plt.plot(epochs, val_loss1, label='Shallow Val Loss')\n",
        "plt.plot(epochs, loss2, label='VGG Train Loss')\n",
        "plt.plot(epochs, val_loss2, label='VGG Val Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Comment on the observation**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzXmO1WoSKMY"
      },
      "source": [
        "*   Use predict function to predict the output for the test split\n",
        "*   Plot the confusion matrix for the new model and comment on the class confusions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DObaoxhaSMUg",
        "outputId": "11fc5e70-c39c-41a4-d58f-33f7b14568eb"
      },
      "outputs": [],
      "source": [
        "# Predict probabilities for the test set\n",
        "y_pred_probs = vgg_model.predict(x_test)  # model can be either shallow or deep model\n",
        "\n",
        "# Convert probabilities to class labels (0 to 9)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# converting one-hot encoded test labels to class labels\n",
        "y_true = np.argmax(y_test, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "kv6h3Wo_PLHJ",
        "outputId": "32316a63-9524-462b-96c0-48160d153528"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Class names for display\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix - VGG Model\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUBrvRomU5O_"
      },
      "source": [
        "**Comment here :**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffwVz-FLSNG7"
      },
      "source": [
        "*    Print the test accuracy for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4WX3_uLSN5I",
        "outputId": "410b531f-3e5d-42c9-f871-bfffe333f443"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = vgg_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Test Accuracy for VGG Model: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dySqfA6PVBjQ"
      },
      "source": [
        "## Define the complete VGG architecture.\n",
        "\n",
        "Stack two convolutional layers with 64 filters, each of 3 x 3 followed by max pooling layer.\n",
        "\n",
        "Stack two more convolutional layers with 128 filters, each of 3 x 3, followed by max pooling, followed by two more convolutional layers with 256 filters, each of 3 x 3, followed by max pooling.\n",
        "\n",
        "Flatten the output of the previous layer and add a dense layer with 128 units before the classification layer.\n",
        "\n",
        "For all the layers, use ReLU activation function.\n",
        "\n",
        "Use same padding for the layers to ensure that the height and width of each layer output matches the input\n",
        "\n",
        "*   Change the size of input to 64 x 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylzRId0lPopI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.image import resize\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.backend import clear_session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSC_juI5P711",
        "outputId": "15ef9934-89e1-4179-f962-5154d9c798b4"
      },
      "outputs": [],
      "source": [
        "vgg_model_cmplt = Sequential([\n",
        "\n",
        "    # Two conv layers with 64 filters + MaxPooling\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 3)),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Two conv layers with 128 filters + MaxPooling\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Two conv layers with 256 filters + MaxPooling\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Classifier\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # 10 classes for CIFAR-10\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm35siILFNT0"
      },
      "outputs": [],
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH4lDVBuVA_Q"
      },
      "outputs": [],
      "source": [
        "# Your code here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_B8kJGWhcM"
      },
      "source": [
        "*   Compile the model using categorical_crossentropy loss, SGD optimizer and use 'accuracy' as the metric.\n",
        "*   Use the above defined model to train CIFAR-10 and train the model for 10 epochs with a batch size of 512.\n",
        "*   Predict the output for the test split and plot the confusion matrix for the new model and comment on the class confusions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Uq-tDPKQgJR",
        "outputId": "bced47b1-6c7f-4894-b813-b4f17b6221ae"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import SGD\n",
        "from tensorflow.image import resize\n",
        "\n",
        "# Resize images to 64x64\n",
        "x_train_resized = resize(x_train, (64, 64))\n",
        "x_test_resized = resize(x_test, (64, 64))\n",
        "\n",
        "\n",
        "vgg_model_cmplt.compile(optimizer = SGD(learning_rate=0.01, momentum=0.9),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "vgg_model_cmplt.summary()\n",
        "\n",
        "\n",
        "history_vgg_model_cmplt = vgg_model_cmplt.fit(x_train_resized, y_train,\n",
        "                                      epochs=50,\n",
        "                                      batch_size=512,\n",
        "                                      validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4elnDWnjEbmO",
        "outputId": "ff550467-9027-4c88-8684-2fea906b18dd"
      },
      "outputs": [],
      "source": [
        "# Predict probabilities\n",
        "y_pred_probs_cmp = vgg_model_cmplt.predict(x_test_resized)\n",
        "\n",
        "# Convert to predicted class labels\n",
        "y_pred_classes_cmplt = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Convert true labels from one-hot to class labels\n",
        "y_true_classes_cmplt = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "1zCPQhXFbZkj",
        "outputId": "75b84c8f-b5f1-4233-e199-0ab499381917"
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true_classes_cmplt, y_pred_classes_cmplt)\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "#plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap='Reds', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix - Full VGG Model\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dlzFt0SXGDQ"
      },
      "source": [
        "# Understanding deep networks\n",
        "\n",
        "*   What is the use of activation functions in network? Why is it needed?\n",
        "*   We have used softmax activation function in the exercise. There are other activation functions available too. What is the difference between sigmoid activation and softmax activation?\n",
        "*   What is the difference between categorical crossentropy and binary crossentropy loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPy_1EWXX6fp"
      },
      "source": [
        "**Write the answers below :**\n",
        "\n",
        "1 - Use of activation functions:\n",
        "It defines the output of a neuron in a neural network based on its input.\n",
        "It adds non-linearity\n",
        "\n",
        "_\n",
        "\n",
        "2 - Key Differences between sigmoid and softmax:\n",
        "Sigmoid is used for binary or multi-label classification which gives independent probabilities between 0 and 1 for each output.\n",
        "\n",
        "softmax is also used for multi-label classification that produces a probability distribution across classes that sums to 1\n",
        "_\n",
        "\n",
        "3 - Key Differences between categorical crossentropy and binary crossentropy loss:\n",
        "\n",
        "\n",
        "_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5968b2f6"
      },
      "source": [
        "**Comment on the class confusions for the complete VGG model:**\n",
        "\n",
        "*(Double-click or enter to edit)*\n",
        "\n",
        "..."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
